{
    "meta": {
        "poster_title": "Earth Mover's Distance based Similarity Search at Scale",
        "authors": "Yu Tang, Leong Hou U, Yilun Cai, Nikos Mamoulis, Reynold Cheng",
        "affiliations": "The University of Hong Kong, University of Macau"
    },
    "sections": [
        {
            "title": "Poster Title",
            "content": "Earth Mover's Distance based Similarity Search at Scale\n\nYu Tang, Leong Hou U, Yilun Cai, Nikos Mamoulis, Reynold Cheng\nThe University of Hong Kong, University of Macau"
        },
        {
            "title": "Introduction & Motivation",
            "content": "Earth Mover's Distance (EMD) is a robust similarity measure for multidimensional histograms, offering better distinguishability than classic measures like Euclidean distance. It is widely used in multimedia databases, computer vision, and machine learning. However, EMD's high computational cost, typically requiring super-cubic time, restricts its scalability. EMD-based similarity searches usually adopt a filter-and-refinement framework. While extensive research has focused on creating tighter lower bounds to prune more candidates in the filter step, the refinement step remains the performance bottleneck. For large-scale datasets, even with a high filtering ratio (e.g., 99%), the cost of exact EMD calculations for the remaining candidates is prohibitive. This paper focuses on optimizing the refinement phase. We propose three key techniques: (i) adapting an efficient min-cost flow algorithm, Simplified Graph Incremental Algorithm (SIA), for EMD computation, (ii) a progressive bounding (PB) technique that uses a dynamic distance bound to terminate EMD calculations early, and (iii) a dynamic refinement ordering (DRO) technique that concurrently refines multiple candidates to reduce needless computations. These techniques are orthogonal to existing filtering methods and can reduce similarity query costs by orders of magnitude."
        },
        {
            "title": "Preliminaries",
            "content": "Given two normalized histograms, q and p, the Earth Mover's Distance (EMD) is the minimum cost to transform one into the other. It is modeled as a min-cost flow (MCF) problem on a bipartite network where vertices represent histogram bins. The cost of moving 'earth' between bins is given by a ground distance matrix. The Successive Shortest Path (SSP) algorithm is a common method for solving MCF. SSP iteratively finds the minimum-cost feasible path in the flow network and augments the maximum possible flow along it. This process repeats until all flow from q has been moved to p. The complexity of SSP is high, requiring O(F|E| log |V|) time, where F is the total flow. A key challenge is that each path augmentation can alter the graph, requiring repeated shortest path searches on the complete bipartite graph, which is quadratic to the number of histogram bins.\n\nEMD similarity queries are typically evaluated using a filter-and-refinement framework. In the filter phase, cheap-to-compute lower bounds of the EMD are used to prune unpromising candidates. For a k-NN query, a pruning threshold θ is maintained, representing the distance to the current k-th nearest neighbor. Any object whose EMD lower bound exceeds θ is filtered. Objects that survive the filter phase proceed to the refinement step, where their exact EMD is computed. This refinement step is the bottleneck we aim to optimize."
        },
        {
            "title": "Scaling EMD Computation",
            "content": "To address the high cost of EMD computation, we adapt the Simplified Graph Incremental Algorithm (SIA), which is an optimized version of SSP. Unlike SSP, which operates on the complete bipartite graph, SIA incrementally constructs a much smaller partial flow graph. It begins with an empty graph and adds edges in ascending order of their costs as needed. At each step, SIA finds the shortest path in the current partial graph. A distance bound, derived from the costs of edges not yet in the partial graph, is used to guarantee that the path found in the partial graph is globally optimal. If the current shortest path's cost is less than this bound, the path is valid and flow is augmented. Otherwise, SIA expands the partial graph by adding the next cheapest edge and repeats the search. This incremental approach significantly reduces the search space and computational cost, as the partial graph is typically much smaller than the complete one, making it highly scalable for histograms with a large number of bins."
        },
        {
            "title": "Progressive Bounding (PB)",
            "content": "Although SIA is efficient for a single EMD calculation, we observe that over 90% of its execution time is spent in the last 20% of its iterations, as the partial graph grows and shortest path searches become expensive. To exploit this, we introduce Progressive Bounding (PB), a technique to terminate SIA early for candidates that will not make it into the final k-NN result. We define a running lower bound, emd-, which is updated throughout the SIA process. This bound consists of two parts: the actual cost of the flow augmented so far, and an estimated cost for the remaining flow yet to be augmented. The estimated cost is calculated based on the cost of the most recent augmented path from each source bin, leveraging the property that path costs from a given bin are monotonically non-decreasing. At each iteration of SIA, we update emd- and compare it against the current k-NN pruning threshold θ. If emd- ≥ θ, we can safely terminate the EMD calculation for the current candidate, as its final EMD will be no smaller than θ. This allows us to prune unpromising candidates mid-refinement, avoiding the most computationally expensive final iterations of SIA and drastically reducing overall query time."
        },
        {
            "title": "Dynamic Refinement Ordering (DRO)",
            "content": "The effectiveness of PB depends on having a tight pruning threshold θ early in the query process. However, the standard filter-and-refinement framework processes candidates sequentially, and the order is not optimal for discovering the true nearest neighbors quickly. To address this, we propose Dynamic Refinement Ordering (DRO), a strategy that refines multiple candidates concurrently. DRO maintains a priority layer (PL) of the most promising candidates that have passed the filter step. Instead of fully refining one candidate at a time, DRO interleaves the SIA computations for all candidates in the PL. In each step, it performs a small amount of work (a few path augmentations) on the candidate that is currently most promising—for instance, the one with the lowest running lower bound emd-. This helps to quickly obtain good estimates for both the lower and upper bounds (emd- and emd+) for many candidates. A tight running upper bound emd+ for a candidate can be used to update and lower the global pruning threshold θ. A tighter θ enables more effective pruning, not only for new candidates in the filter phase but also for the candidates currently being refined in the PL via the PB technique. By dynamically reordering and concurrently processing refinements, DRO converges on the final k-NN set faster and with significantly less overall computation."
        },
        {
            "title": "Experimental Results",
            "content": "We conducted extensive experiments on six real-world image datasets, with cardinalities up to 3 million and histogram dimensionalities up to 1024 bins. Our evaluation shows that: \n1. SIA consistently outperforms other black-box EMD computation methods (like SSP and Transportation Simplex) by a significant margin, establishing it as the best baseline for the refinement phase.\n2. Our Progressive Bounding (PB) technique provides a large performance boost over the baseline SIA. The improvement is more pronounced on larger datasets and higher-dimensional histograms, where the later stages of SIA become extremely expensive.\n3. Dynamic Refinement Ordering (DRO) offers a stable and significant improvement over PB (40%-60%), demonstrating the effectiveness of concurrent refinement and dynamic reordering. DRO's performance is very close to that of an oracle method with optimal ordering, indicating it is highly effective.\n4. Compared to state-of-the-art frameworks using standard EMD solvers, our DRO approach is up to two orders of magnitude faster. It scales gracefully with both dataset cardinality and histogram dimensionality, making EMD-based similarity search practical for large-scale, high-dimensional applications."
        },
        {
            "title": "Conclusion",
            "content": "We proposed a suite of techniques to optimize the bottleneck refinement phase of EMD-based similarity search. By adapting an efficient incremental algorithm (SIA), introducing a progressive bounding method (PB) for early termination, and developing a dynamic refinement ordering strategy (DRO) for concurrent processing, we significantly accelerate similarity queries. Our experimental results confirm that these methods reduce query costs by up to two orders of magnitude compared to the state-of-the-art, enabling scalable and efficient EMD-based search on large, high-dimensional histogram datasets. Our framework is general and can be applied to different EMD problem variants and integrated with existing filtering techniques."
        }
    ]
}